{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression sample for Spark\n",
    "- envs: Toree (scala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@6aeee626"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|fail|temperature|\n",
      "+----+-----------+\n",
      "|0   |60         |\n",
      "|0   |56         |\n",
      "+----+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [fail: int, temperature: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[fail: int, temperature: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.createDataFrame(Seq(\n",
    "    (0, 60),\n",
    "    (0, 56),\n",
    "    (0, 54),\n",
    "    (0, 62),\n",
    "    (0, 61),\n",
    "    (0, 53),\n",
    "    (0, 55),\n",
    "    (0, 62),\n",
    "    (0, 64),\n",
    "    (1, 73),\n",
    "    (1, 78),\n",
    "    (1, 67),\n",
    "    (1, 68),\n",
    "    (1, 78)\n",
    ")).toDF(\"fail\" , \"temperature\")\n",
    "df.show(2, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fail: integer (nullable = false)\n",
      " |-- temperature: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.regression.{LinearRegression, LinearRegressionModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features = vecAssembler_f89fa0469ae7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_f89fa0469ae7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Defining features\n",
    "val features = new VectorAssembler()\n",
    "  .setInputCols(Array(\"temperature\"))\n",
    "  .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr = linReg_c9b5b05778f4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "linReg_c9b5b05778f4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Define model to use\n",
    "val lr = new LinearRegression().setLabelCol(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aggregationDepth: suggested depth for treeAggregate (>= 2) (default: 2)\n",
       "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0)\n",
       "featuresCol: features column name (default: features)\n",
       "fitIntercept: whether to fit an intercept term (default: true)\n",
       "labelCol: label column name (default: label, current: fail)\n",
       "maxIter: maximum number of iterations (>= 0) (default: 100)\n",
       "predictionCol: prediction column name (default: prediction)\n",
       "regParam: regularization parameter (>= 0) (default: 0.0)\n",
       "solver: the solver algorithm for optimization. If this is not set or empty, default value is 'auto' (default: auto)\n",
       "standardization: whether to standardize the training features before fitting ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// 설정할 수 있는 Params\n",
    "lr.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = pipeline_8bd03406c210\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_8bd03406c210"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a pipeline that associates the model with the data processing sequence\n",
    "val pipeline = new Pipeline().setStages(Array(features, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_8bd03406c210\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_8bd03406c210"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Run the Model\n",
    "val model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.24965353110553395\n",
      "r2:    0.7285317871929219\n",
      "Model: Y = 0.05114497726003437 * X + -2.8978696241921877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "linRegModel = linReg_c9b5b05778f4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "linReg_c9b5b05778f4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Parameters는 문서를 보고 확인하자.\n",
    "// https://spark.apache.org/docs/2.2.0/api/scala/index.html#org.apache.spark.ml.regression.LinearRegressionSummary\n",
    "val linRegModel = model.stages(1).asInstanceOf[LinearRegressionModel]\n",
    "println(s\"RMSE:  ${linRegModel.summary.rootMeanSquaredError}\")\n",
    "println(s\"r2:    ${linRegModel.summary.r2}\")\n",
    "println(s\"Model: Y = ${linRegModel.coefficients(0)} * X + ${linRegModel.intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------------------+\n",
      "|temperature|fail|          prediction|\n",
      "+-----------+----+--------------------+\n",
      "|         60|   0| 0.17082901140987428|\n",
      "|         56|   0|-0.03375089763026...|\n",
      "|         54|   0|-0.13604085215033157|\n",
      "|         62|   0| 0.27311896592994334|\n",
      "|         61|   0|  0.2219739886699088|\n",
      "|         53|   0| -0.1871858294103661|\n",
      "|         55|   0|-0.08489587489029748|\n",
      "|         62|   0| 0.27311896592994334|\n",
      "|         64|   0| 0.37540892045001195|\n",
      "|         73|   1|  0.8357137157903214|\n",
      "|         78|   1|  1.0914386020904931|\n",
      "|         67|   1|  0.5288438522301151|\n",
      "|         68|   1|  0.5799888294901496|\n",
      "|         78|   1|  1.0914386020904931|\n",
      "+-----------+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result = [temperature: int, fail: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[temperature: int, fail: int ... 1 more field]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = model.transform(df).select(\"temperature\", \"fail\", \"prediction\")\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala Toree QM Spark k8s Small(dm:4G, em:2G, e:64)",
   "language": "scala",
   "name": "scala_spark_qm_k8s_small"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
