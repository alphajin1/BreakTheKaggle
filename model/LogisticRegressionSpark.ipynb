{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression sample for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@51890b9c"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [PassengerId: string, Survived: string ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: string, Survived: string ... 10 more fields]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", true).csv(\"/user/jay-n/SampleData/titanic_train.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adf = [PassengerId: string, Survived: string ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: string, Survived: string ... 10 more fields]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val adf = df.filter($\"Age\".isNotNull).filter($\"Sex\".isNotNull)\n",
    "println(df.count())\n",
    "println(adf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bdf = [Age: int, Sex: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Age: int, Sex: string ... 1 more field]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bdf = adf.selectExpr(\"cast(Age as int) Age\", \"Sex\", \"cast(Survived as int) Survived\")\n",
    "bdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+--------+-------------+\n",
      "|Age|Sex   |Survived|SexIndex|SexVec       |\n",
      "+---+------+--------+--------+-------------+\n",
      "|22 |male  |0       |0.0     |(1,[0],[1.0])|\n",
      "|38 |female|1       |1.0     |(1,[],[])    |\n",
      "|26 |female|1       |1.0     |(1,[],[])    |\n",
      "+---+------+--------+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "indexer = strIdx_a2a1e715a5ba\n",
       "indexed = [Age: int, Sex: string ... 2 more fields]\n",
       "encoder = oneHot_4be47d4899da\n",
       "cdf = [Age: int, Sex: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Age: int, Sex: string ... 3 more fields]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n",
    "\n",
    "val indexer = new StringIndexer()\n",
    "  .setInputCol(\"Sex\")\n",
    "  .setOutputCol(\"SexIndex\")\n",
    "  .fit(tdf)\n",
    "val indexed = indexer.transform(bdf)\n",
    "\n",
    "val encoder = new OneHotEncoder()\n",
    "  .setInputCol(\"SexIndex\")\n",
    "  .setOutputCol(\"SexVec\")\n",
    "\n",
    "val cdf = encoder.transform(indexed)\n",
    "cdf.show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- SexIndex: double (nullable = true)\n",
      " |-- SexVec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2 VectorAssembler (TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+--------+-------------+----------+\n",
      "|Age|Sex   |Survived|SexIndex|SexVec       |features  |\n",
      "+---+------+--------+--------+-------------+----------+\n",
      "|22 |male  |0       |0.0     |(1,[0],[1.0])|[22.0,1.0]|\n",
      "|38 |female|1       |1.0     |(1,[],[])    |[38.0,0.0]|\n",
      "|26 |female|1       |1.0     |(1,[],[])    |[26.0,0.0]|\n",
      "+---+------+--------+--------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "assembler = vecAssembler_19346505d429\n",
       "output = [Age: int, Sex: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Age: int, Sex: string ... 4 more fields]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"Age\", \"SexVec\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val output = assembler.transform(cdf)\n",
    "output.show(3, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler = vecAssembler_939c185f30a0\n",
       "lr = logreg_423e25e14ba5\n",
       "pipeline = pipeline_1004ed49807a\n",
       "model = pipeline_1004ed49807a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_1004ed49807a"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"Age\", \"SexVec\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val lr = new LogisticRegression().setLabelCol(\"Survived\")\n",
    "val pipeline = new Pipeline().setStages(Array(assembler, lr))\n",
    "\n",
    "val model = pipeline.fit(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecAssembler_939c185f30a0\n",
      "logreg_423e25e14ba5\n"
     ]
    }
   ],
   "source": [
    "println(model.stages(0))\n",
    "println(model.stages(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logRegModel = logreg_423e25e14ba5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_423e25e14ba5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegressionModel\n",
    "val logRegModel = model.stages(1).asInstanceOf[LogisticRegressionModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients: -0.0054616405614571475  -2.4659403174938883  \n",
      "intercepts: [1.2782309194083987]\n"
     ]
    }
   ],
   "source": [
    "// coefficient(계수), intercept(절편)\n",
    "println(s\"coefficients: ${logRegModel.coefficientMatrix}\")\n",
    "println(s\"intercepts: ${logRegModel.interceptVector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6754313479380432\n",
      "0.6331096467875821\n",
      "0.5933719022991755\n",
      "0.5462606025000956\n",
      "0.542209931657562\n",
      "0.532297514278512\n",
      "0.5255861640910967\n",
      "0.5251767386069403\n",
      "0.525172397326206\n",
      "0.5251722630081502\n",
      "0.5251722562852661\n",
      "0.5251722562159999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainingSummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary@44b439cd\n",
       "objectiveHistory = Array(0.6754313479380432, 0.6331096467875821, 0.5933719022991755, 0.5462606025000956, 0.542209931657562, 0.532297514278512, 0.5255861640910967, 0.5251767386069403, 0.525172397326206, 0.5251722630081502, 0.5251722562852661, 0.5251722562159999)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(0.6754313479380432, 0.6331096467875821, 0.5933719022991755, 0.5462606025000956, 0.542209931657562, 0.532297514278512, 0.5255861640910967, 0.5251767386069403, 0.525172397326206, 0.5251722630081502, 0.5251722562852661, 0.5251722562159999)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Objective Function 체크 (학습이 잘 되고 있는지)\n",
    "import org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegression}\n",
    "val trainingSummary = logRegModel.summary\n",
    "val objectiveHistory = trainingSummary.objectiveHistory\n",
    "println(\"objectiveHistory:\")\n",
    "objectiveHistory.foreach(loss => println(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|                 0.0|0.006896551724137931|\n",
      "|                 0.0|0.013793103448275862|\n",
      "|0.009433962264150943|0.020689655172413793|\n",
      "| 0.01179245283018868| 0.02413793103448276|\n",
      "| 0.01179245283018868|0.041379310344827586|\n",
      "| 0.01179245283018868| 0.05517241379310345|\n",
      "|0.014150943396226415| 0.05862068965517241|\n",
      "|0.014150943396226415| 0.06206896551724138|\n",
      "| 0.01650943396226415| 0.06551724137931035|\n",
      "|0.025943396226415096| 0.06551724137931035|\n",
      "| 0.02830188679245283| 0.06551724137931035|\n",
      "|0.030660377358490566| 0.06551724137931035|\n",
      "|0.030660377358490566| 0.07241379310344828|\n",
      "| 0.03537735849056604| 0.08275862068965517|\n",
      "| 0.03537735849056604| 0.09655172413793103|\n",
      "| 0.03773584905660377| 0.11379310344827587|\n",
      "| 0.04009433962264151|  0.1310344827586207|\n",
      "| 0.05188679245283019| 0.15862068965517243|\n",
      "| 0.05188679245283019| 0.18275862068965518|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.7716371177618736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "binarySummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary@44b439cd\n",
       "roc = [FPR: double, TPR: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[FPR: double, TPR: double]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// ROC Curve 정보\n",
    "val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]\n",
    "val roc = binarySummary.roc\n",
    "roc.show()\n",
    "println(s\"areaUnderROC: ${binarySummary.areaUnderROC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fMeasure = [threshold: double, F-Measure: double]\n",
       "maxFMeasure = 0.7414965986394558\n",
       "bestThreshold = 0.2221382134617676\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_423e25e14ba5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val fMeasure = binarySummary.fMeasureByThreshold\n",
    "val maxFMeasure = fMeasure.select(max(\"F-Measure\")).head().getDouble(0)\n",
    "val bestThreshold = fMeasure.where($\"F-Measure\" === maxFMeasure).select(\"threshold\").head().getDouble(0)\n",
    "logRegModel.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+--------+-------------+----------+----------------------------------------+----------------------------------------+----------+\n",
      "|Age|Sex   |Survived|SexIndex|SexVec       |features  |rawPrediction                           |probability                             |prediction|\n",
      "+---+------+--------+--------+-------------+----------+----------------------------------------+----------------------------------------+----------+\n",
      "|22 |male  |0       |0.0     |(1,[0],[1.0])|[22.0,1.0]|[1.3078654904375469,-1.3078654904375469]|[0.7871557559895479,0.212844244010452]  |0.0       |\n",
      "|38 |female|1       |1.0     |(1,[],[])    |[38.0,0.0]|[-1.070688578073027,1.070688578073027]  |[0.2552721577194062,0.7447278422805937] |1.0       |\n",
      "|26 |female|1       |1.0     |(1,[],[])    |[26.0,0.0]|[-1.1362282648105129,1.1362282648105129]|[0.24301352898468334,0.7569864710153167]|1.0       |\n",
      "|35 |female|1       |1.0     |(1,[],[])    |[35.0,0.0]|[-1.0870734997573985,1.0870734997573985]|[0.25216975794140584,0.747830242058594] |1.0       |\n",
      "|35 |male  |0       |0.0     |(1,[0],[1.0])|[35.0,1.0]|[1.3788668177364898,-1.3788668177364898]|[0.7988089445495605,0.20119105545043953]|0.0       |\n",
      "|54 |male  |0       |0.0     |(1,[0],[1.0])|[54.0,1.0]|[1.4826379884041756,-1.4826379884041756]|[0.8149707026608984,0.18502929733910167]|0.0       |\n",
      "|2  |male  |0       |0.0     |(1,[0],[1.0])|[2.0,1.0] |[1.1986326792084039,-1.1986326792084039]|[0.7682814554293046,0.23171854457069543]|1.0       |\n",
      "|27 |female|1       |1.0     |(1,[],[])    |[27.0,0.0]|[-1.1307666242490557,1.1307666242490557]|[0.24401965086549499,0.755980349134505] |1.0       |\n",
      "|14 |female|1       |1.0     |(1,[],[])    |[14.0,0.0]|[-1.2017679515479986,1.2017679515479986]|[0.23116085706976328,0.7688391429302368]|1.0       |\n",
      "|4  |female|1       |1.0     |(1,[],[])    |[4.0,0.0] |[-1.2563843571625701,1.2563843571625701]|[0.22159693288105425,0.7784030671189457]|1.0       |\n",
      "+---+------+--------+--------+-------------+----------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result = [Age: int, Sex: string ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Age: int, Sex: string ... 7 more fields]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = model.transform(cdf)\n",
    "result.show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala Toree QM Spark k8s Small(dm:4G, em:2G, e:64)",
   "language": "scala",
   "name": "scala_spark_qm_k8s_small"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
